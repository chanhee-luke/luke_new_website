---
title: about
---

<div class="about-header">
<a class="about-header-image">
<img class="default-image" src="https://s2.loli.net/2024/04/16/FPDGJzvpMR1eXTZ.png" >
<img class="hover-image" src="https://s2.loli.net/2024/04/17/Y3A9qcdQvGXpNhC.jpg" >
</a>

<div>
<p class="name">Hi, I'm Kai Zhang <img class="about-image" src='https://qpluspicture.oss-cn-beijing.aliyuncs.com/6LjjQA/Hi.gif' alt='Hi' width="24"/></p> 
<p>I'm a second-year PhD student fortunately advised by <a href="https://ysu1989.github.io/">Prof.Yu Su</a> at The Ohio State University.</p>
<p>I'm broadly interested in NLP, Multimodality, and their real-world applications. Here is my (could be outdated) <a href="https://drogozhang.github.io/files/cv_open.pdf">CV</a>.</p>
<!-- <p><i class="fa-solid fa-location-dot"></i> Columbus, OH</p> -->
<p class="find-me">Find me on
    <a class="icon u-url" target="_blank" rel="noopener me" href="https://twitter.com/DrogoKhal4" aria-label="twitter" title="twitter">
        <i class="fa-brands fa-twitter"></i>
    </a>, 
    <a class="icon u-url" target="_blank" rel="noopener me" href="https://www.linkedin.com/in/kai-zhang-43774b196" aria-label="linkedin" title="linkedin">
        <i class="fa-brands fa-linkedin"></i>
    </a>, 
    <a class="icon u-url" target="_blank" rel="noopener me" href="https://github.com/drogozhang" aria-label="github" title="github">
        <i class="fa-brands fa-github"></i>
    </a>and 
    <a class="icon" target="_blank" rel="noopener" href="https://scholar.google.com/citations?user=sDnAIsgAAAAJ&hl=en" aria-label="graduation-cap" title="graduation-cap">
        <i class="fa-solid fa-graduation-cap"></i>
    </a>.
</p>
</div>
</div>


# Selected Publications

See full list in [Publications](/archives).

<div id="selected_pub">
<ul class="post-list">
    <li class="post-item">
        <p class="paper-name">MagicLens: Self-Supervised Image Retrieval with Open-Ended Instructions</p>
        <p class="authors"><span>Kai Zhang</span>, Yi Luan, Hexiang Hu, Kenton Lee, Siyuan Qiao, Wenhu Chen, Yu Su, Ming-Wei Chang</p>
        <p class="links">
            <span class="tag">Preprint</span>
            <a href="https://arxiv.org/abs/2403.19651">ArXiv</a>
            <a href="https://open-vision-language.github.io/MagicLens/">Website</a>
        </p>
    </li>
    <li class="post-item">
        <p class="paper-name">MMMU: A Massive Multi-discipline Multimodal Understanding and Reasoning Benchmark for Expert AGI</p>
        <p class="authors">Xiang Yue*, Yuansheng Ni*, <span>Kai Zhang</span>*, Tianyu Zheng*, Ruoqi Liu, Ge Zhang, Samuel Stevens, Dongfu Jiang, Weiming Ren, Yuxuan Sun, Cong Wei, Botao Yu, Ruibin Yuan, Renliang Sun, Ming Yin, Boyuan Zheng, Zhenzhu Yang, Yibo Liu, Wenhao Huang, Huan Sun, Yu Su, Wenhu Chen</p>
        <p class="links">
            <span class="tag">CVPR’24</span>
            <span class="spotlight">Oral(0.78%)</span>
            <a href="https://arxiv.org/abs/2311.16502">ArXiv</a>
            <a href="https://mmmu-benchmark.github.io/">Website</a>
            <a href="https://github.com/MMMU-Benchmark/MMMU">Code</a>
            <a href="https://huggingface.co/datasets/MMMU/MMMU">Data</a>
        </p>
    </li>
    <li class="post-item">
        <p class="paper-name">Adaptive Chameleon or Stubborn Sloth: Revealing the Behavior of Large Language Models in Knowledge Conflicts</p>
        <p class="authors">Jian Xie*, <span>Kai Zhang</span>*, Jiangjie Chen, Renze Lou, Yu Su</p>
        <p class="links">
            <span class="tag">ICLR’24</span>
            <span class="spotlight">Spotlight (5%)</span>
            <a href="https://arxiv.org/abs/2305.13300">ArXiv</a>
            <a href="https://github.com/OSU-NLP-Group/LLM-Knowledge-Conflict">Code</a>
        </p>
    </li>
    <li class="post-item">
        <p class="paper-name">MagicBrush: A Manually Annotated Dataset for Instruction-Guided Image Editing</p>
        <p class="authors"><span>Kai Zhang</span>*, Lingbo Mo*, Wenhu Chen, Huan Sun, Yu Su</p>
        <p class="links">
            <span class="tag">NeurIPS’23</span>
            <span class="spotlight">Datasets and Benchmarks</span>
            <a href="https://arxiv.org/abs/2306.10012">ArXiv</a>
            <a href="https://osu-nlp-group.github.io/MagicBrush/">Website</a>
            <a href="https://github.com/OSU-NLP-Group/MagicBrush">Code</a>
            <a href="https://huggingface.co/datasets/osunlp/MagicBrush">Data</a>
        </p>
    </li>
</ul>
</div>

# Invited Talks
<div class="invited_talks_item">
    <p class="talk_name">Large Language Models in Knowledge Conflicts <a class="slides_link" href="https://drogozhang.github.io/files/paper_slides/Knowledge_Conflicts_in_LLMs_070324.pdf">Slides</a></p>
    <li class="list">Mar 2024, AI Time Seminar</li>
</div>
<div class="invited_talks_item">
    <p class="talk_name">TravelPlanner: A Benchmark for Real-World Planning with Language Agents <a class="slides_link" href="https://drogozhang.github.io/files/paper_slides/TravelPlanner_140224.pdf">Slides</a></p>
    <li class="list">Feb 2024, Google Real World Journeys Group</li>
</div>
<div class="invited_talks_item">
    <p class="talk_name">Task Alignment in Instruction-tuned LLMs for Relation Extraction (LLM-QA4RE) <a class="slides_link" href="https://drogozhang.github.io/files/paper_slides/QA4RE_ACL23.pdf">Slides</a></p>
    <li class="list">Mar 2023, University of Notre Dame NLP Seminar</li>
    <li class="list">May 2023, AI TIME Seminar</li>
    <li class="list">Jul 2023, ACL’23 Matching Workshop</li>
</div>

# PC Member/Reviewer:

ARR (since 22); CCKS’22-23; EMNLP’22-23; ACL’23; NAACL’24
WWW’23; KDD’23; SDM’24
AAAI’23-24; NeurIPS’23; ICLR’24; ICML’24; COLM’24
CVPR’24

# Contact
**Email**: [LAST_NAME].13253@osu.edu OR drogo[LAST_NAME]@gmail.com

Feel free to contact me if you are interested in my research or want to discuss relevant research topic :)

<br />
<br />