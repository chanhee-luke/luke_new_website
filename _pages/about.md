---
permalink: /
layout: archive
title: "About me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
I am a first-year PhD student fortunately advised by Prof. [Yu Su](https://ysu1989.github.io) at The Ohio State University. Before starting my PhD journey, I did NLP research under the supervision of Prof. [Zhiyuan Liu](http://nlp.csai.tsinghua.edu.cn/~lzy/) at Tsinghua University, Prof. [Soroush Vosoughi](https://www.cs.dartmouth.edu/~soroush/) at Dartmouth College, and Dr. [Daxin Jiang](https://www.microsoft.com/en-us/research/people/djiang/) at Microsoft STCA Semantics and Knowledge Team. 
<!-- Here is my [CV](/files/cv_open.pdf) (updated in Jan 2023).-->

I am broadly interested in Natural Language Processing and its real-world applications, currently focusing on Knowledge, (Large) Language Models, and their interplay.

<!--  I am disinclined to pursue research topics without the potential for real-world applicability. To align with the objective of practical research, I have publicly released all of my source code and will keep doing so.-->


## News
<!-- - 03/2023: New Survey on [Instruction Learning](https://arxiv.org/pdf/2303.10475.pdf), feedbacks and comments are more than welcome!  -->

- 05/2023: Unified Retriever was accepted to KDD'23.
- 05/2023: **My best work so far**, LLM-QA4RE was accepted to Findings of ACL'23!
- 03/2023: <font color="#dd0000">A comprehensive</font> **[reading list](https://github.com/RenzeLou/awesome-instruction-learning)** & **[survey](https://arxiv.org/abs/2303.10475)** <font color="#dd0000">on Instruction Learning!</font>
- 01/2023: LED Retriever, was accepted to WWW'23.
- 02/2022: Started to work at Microsoft as a Research Intern.
- 08/2021: Multi-Task Auto Auxiliary Task Selection was accepted to EMNLP'21.
- 08/2021: Unified and Incremental SimRank was accepted to TKDE.
- 05/2021: Multi-Lingual Transformer Analysis was accepted to ACL'21.
- 03/2021: Open Hierarchical Relation Extraction was accepted to NAACL-HLT'21.


## Selected Publications
Please refer to [Publications](/publications/) for the full list

**Aligning Instruction Tasks Unlocks Large Language Models as Zero-Shot Relation Extractors** 

<u>Kai Zhang</u>, Bernal Jiménez Gutiérrez, and Yu Su. In Findings of ACL'23 \[[Paper](https://arxiv.org/pdf/2305.11159.pdf)\] [[Code](https://github.com/OSU-NLP-Group/QA4RE)]

**LED: Lexicon-Enlightened Dense Retriever for Large-Scale Retrieval**

<u>Kai Zhang</u>, Chongyang Tao, Tao Shen, Can Xu, Xiubo Geng, Binxing Jiao, and Daxin Jiang. In WWW'23 (**Oral**) \[[Paper](https://arxiv.org/pdf/2208.13661.pdf)\] [[Code](https://github.com/drogozhang/LED)]

**Contributions of Transformer Attention Heads in Multi- and Cross-lingual Tasks**

Weicheng Ma\*, <u>Kai Zhang</u>\*, Renze Lou, Lili Wang, and Soroush Vosoughi. In ACL'21 (**Oral**) \[[Paper](https://aclanthology.org/2021.acl-long.152.pdf)\] \[[Code](https://github.com/hikari-NYU/Contributions-of-Transformer-Attention-Heads-in-Multi--and-Cross-lingual-Tasks)\]

**Open Hierarchical Relation Extraction**

<u>Kai Zhang</u>\*, Yuan Yao\*, Ruobing Xie, Xu Han, Zhiyuan Liu, Fen Lin, Leyu Lin, and Maosong Sun. In NAACL-HLT'21 \[[Paper](https://www.aclweb.org/anthology/2021.naacl-main.452.pdf)\] \[[Code](https://github.com/thunlp/OHRE)\]

## Academic Services

**Secondary Reviewer**: WSDM'21; NAACL-HLT'21; ACL'21; EMNLP'21

**PC Member/Reviewer**: ARR (since 22); CCKS'22; EMNLP'22; AAAI'23; WWW'23; ACL'23; KDD'23; NeurIPS'23

## Talk

**Aligning LLM Instruction Tasks for Zero-Shot Relation Extraction (QA4RE)**

- University of Notre Dame NLP Seminar. March 2023

## Contact

**Email**: `[LAST_NAME].13253@osu.edu` OR `drogo[LAST_NAME]@gmail.com`

Feel free to contact me if you are interested in my research or want to discuss relevant research topic or potential collaborations :)

<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=312&t=tt&d=WWgOfq4agmQMsv-liNWF_IqrTiXrb-1nqoPvyzlC238'></script>